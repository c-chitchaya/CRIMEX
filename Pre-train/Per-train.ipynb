{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731e5a00",
   "metadata": {},
   "source": [
    "ref: https://python3.wannaphong.com/2018/12/named-entity-recognition-ner-pythainlp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684a4ee5",
   "metadata": {},
   "source": [
    "# Instailation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa59413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbca0ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/crimex/miniconda3/lib/python3.10/site-packages (4.26.1)\n",
      "Requirement already satisfied: sentencepiece in /home/crimex/miniconda3/lib/python3.10/site-packages (0.1.97)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: requests in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers) (3.9.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/crimex/.local/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "489823a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn-pycrfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347a1e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pythainlp[full] in /home/crimex/miniconda3/lib/python3.10/site-packages (3.1.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (2.28.1)\n",
      "Requirement already satisfied: thai-nner in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.3)\n",
      "Requirement already satisfied: sefr-cut>=1.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.1)\n",
      "Requirement already satisfied: wunsen>=0.0.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.0.3)\n",
      "Requirement already satisfied: tltk>=1.3.8 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.6.5)\n",
      "Requirement already satisfied: ufal.chu-liu-edmonds>=1.0.2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.22 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.23.5)\n",
      "Requirement already satisfied: fastai<2.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.0.61)\n",
      "Requirement already satisfied: pandas>=0.24 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.5.2)\n",
      "Requirement already satisfied: phunspell>=0.1.6 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.1.6)\n",
      "Requirement already satisfied: epitran>=1.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.24)\n",
      "Requirement already satisfied: symspellpy>=6.7.6 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (6.7.7)\n",
      "Requirement already satisfied: spylls>=0.1.5 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.1.7)\n",
      "Requirement already satisfied: spacy-thai>=0.7.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.7.3)\n",
      "Requirement already satisfied: emoji>=0.5.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (2.2.0)\n",
      "Requirement already satisfied: nlpo3>=1.2.2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.2.6)\n",
      "Requirement already satisfied: attacut>=1.0.4 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.0.6)\n",
      "Requirement already satisfied: gensim>=4.0.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (4.3.1)\n",
      "Requirement already satisfied: transformers>=4.22.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (4.26.1)\n",
      "Requirement already satisfied: nltk>=3.3.* in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.91 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.1.97)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.13.1)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.3.4)\n",
      "Requirement already satisfied: sacremoses>=0.0.41 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.0.53)\n",
      "Requirement already satisfied: pyicu>=2.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (2.10.2)\n",
      "Requirement already satisfied: fairseq>=0.10.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.12.2)\n",
      "Requirement already satisfied: ssg>=0.0.8 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (0.0.8)\n",
      "Requirement already satisfied: oskut>=1.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.3)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (6.0)\n",
      "Requirement already satisfied: onnxruntime>=1.10.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pythainlp[full]) (1.14.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from attacut>=1.0.4->pythainlp[full]) (1.16.0)\n",
      "Requirement already satisfied: fire>=0.1.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from attacut>=1.0.4->pythainlp[full]) (0.5.0)\n",
      "Requirement already satisfied: nptyping>=0.2.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from attacut>=1.0.4->pythainlp[full]) (2.5.0)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from attacut>=1.0.4->pythainlp[full]) (0.6.2)\n",
      "Requirement already satisfied: tqdm in /home/crimex/miniconda3/lib/python3.10/site-packages (from bpemb>=0.3.2->pythainlp[full]) (4.64.1)\n",
      "Requirement already satisfied: marisa-trie in /home/crimex/miniconda3/lib/python3.10/site-packages (from epitran>=1.1->pythainlp[full]) (0.7.8)\n",
      "Requirement already satisfied: panphon>=0.20 in /home/crimex/miniconda3/lib/python3.10/site-packages (from epitran>=1.1->pythainlp[full]) (0.20.0)\n",
      "Requirement already satisfied: setuptools in /home/crimex/miniconda3/lib/python3.10/site-packages (from epitran>=1.1->pythainlp[full]) (59.5.0)\n",
      "Requirement already satisfied: regex in /home/crimex/miniconda3/lib/python3.10/site-packages (from epitran>=1.1->pythainlp[full]) (2022.10.31)\n",
      "Requirement already satisfied: cffi in /home/crimex/.local/lib/python3.10/site-packages (from fairseq>=0.10.0->pythainlp[full]) (1.15.1)\n",
      "Requirement already satisfied: omegaconf<2.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from fairseq>=0.10.0->pythainlp[full]) (2.0.6)\n",
      "Requirement already satisfied: cython in /home/crimex/miniconda3/lib/python3.10/site-packages (from fairseq>=0.10.0->pythainlp[full]) (0.29.33)\n",
      "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /home/crimex/miniconda3/lib/python3.10/site-packages (from fairseq>=0.10.0->pythainlp[full]) (1.0.7)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /home/crimex/miniconda3/lib/python3.10/site-packages (from fairseq>=0.10.0->pythainlp[full]) (2.3.1)\n",
      "Requirement already satisfied: torchaudio>=0.8.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from fairseq>=0.10.0->pythainlp[full]) (0.13.1)\n",
      "Requirement already satisfied: bitarray in /home/crimex/miniconda3/lib/python3.10/site-packages (from fairseq>=0.10.0->pythainlp[full]) (2.7.3)\n",
      "Requirement already satisfied: fastprogress>=0.2.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (1.0.3)\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (7.352.0)\n",
      "Requirement already satisfied: torchvision in /home/crimex/miniconda3/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (0.14.1)\n",
      "Requirement already satisfied: numexpr in /home/crimex/miniconda3/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (2.8.4)\n",
      "Requirement already satisfied: Pillow in /home/crimex/miniconda3/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (9.4.0)\n",
      "Requirement already satisfied: bottleneck in /home/crimex/miniconda3/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (1.3.7)\n",
      "Requirement already satisfied: matplotlib in /home/crimex/miniconda3/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (3.7.1)\n",
      "Requirement already satisfied: scipy in /home/crimex/miniconda3/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (1.10.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/crimex/.local/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (4.11.1)\n",
      "Requirement already satisfied: packaging in /home/crimex/.local/lib/python3.10/site-packages (from fastai<2.0->pythainlp[full]) (23.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from gensim>=4.0.0->pythainlp[full]) (6.3.0)\n",
      "Requirement already satisfied: joblib in /home/crimex/miniconda3/lib/python3.10/site-packages (from nltk>=3.3.*->pythainlp[full]) (1.2.0)\n",
      "Requirement already satisfied: click in /home/crimex/miniconda3/lib/python3.10/site-packages (from nltk>=3.3.*->pythainlp[full]) (8.1.3)\n",
      "Requirement already satisfied: coloredlogs in /home/crimex/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.10.0->pythainlp[full]) (15.0.1)\n",
      "Requirement already satisfied: protobuf in /home/crimex/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.10.0->pythainlp[full]) (3.19.6)\n",
      "Requirement already satisfied: flatbuffers in /home/crimex/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.10.0->pythainlp[full]) (23.3.3)\n",
      "Requirement already satisfied: sympy in /home/crimex/miniconda3/lib/python3.10/site-packages (from onnxruntime>=1.10.0->pythainlp[full]) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in /home/crimex/miniconda3/lib/python3.10/site-packages (from oskut>=1.3->pythainlp[full]) (1.2.2)\n",
      "Requirement already satisfied: pyahocorasick<=1.4.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from oskut>=1.3->pythainlp[full]) (1.4.0)\n",
      "Requirement already satisfied: tensorflow>=2.0.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from oskut>=1.3->pythainlp[full]) (2.11.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/crimex/.local/lib/python3.10/site-packages (from pandas>=0.24->pythainlp[full]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pandas>=0.24->pythainlp[full]) (2022.7.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests>=2.22.0->pythainlp[full]) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests>=2.22.0->pythainlp[full]) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests>=2.22.0->pythainlp[full]) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests>=2.22.0->pythainlp[full]) (1.26.13)\n",
      "Requirement already satisfied: python-crfsuite in /home/crimex/miniconda3/lib/python3.10/site-packages (from sefr-cut>=1.1->pythainlp[full]) (0.9.8)\n",
      "Requirement already satisfied: deplacy>=2.0.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy-thai>=0.7.1->pythainlp[full]) (2.0.5)\n",
      "Requirement already satisfied: ufal.udpipe>=1.2.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy-thai>=0.7.1->pythainlp[full]) (1.3.0.1)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy-thai>=0.7.1->pythainlp[full]) (3.5.1)\n",
      "Requirement already satisfied: editdistpy>=0.1.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from symspellpy>=6.7.6->pythainlp[full]) (0.1.3)\n",
      "Requirement already satisfied: sklearn in /home/crimex/miniconda3/lib/python3.10/site-packages (from tltk>=1.3.8->pythainlp[full]) (0.0.post1)\n",
      "Requirement already satisfied: sklearn-crfsuite in /home/crimex/miniconda3/lib/python3.10/site-packages (from tltk>=1.3.8->pythainlp[full]) (0.3.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/crimex/miniconda3/lib/python3.10/site-packages (from torch>=1.0.0->pythainlp[full]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/crimex/miniconda3/lib/python3.10/site-packages (from torch>=1.0.0->pythainlp[full]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/crimex/miniconda3/lib/python3.10/site-packages (from torch>=1.0.0->pythainlp[full]) (11.10.3.66)\n",
      "Requirement already satisfied: typing-extensions in /home/crimex/miniconda3/lib/python3.10/site-packages (from torch>=1.0.0->pythainlp[full]) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/crimex/miniconda3/lib/python3.10/site-packages (from torch>=1.0.0->pythainlp[full]) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in /home/crimex/miniconda3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.0.0->pythainlp[full]) (0.37.1)\n",
      "Requirement already satisfied: filelock in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers>=4.22.1->pythainlp[full]) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers>=4.22.1->pythainlp[full]) (0.13.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from transformers>=4.22.1->pythainlp[full]) (0.13.2)\n",
      "Requirement already satisfied: khanaa>=0.0.6 in /home/crimex/miniconda3/lib/python3.10/site-packages (from wunsen>=0.0.3->pythainlp[full]) (0.0.6)\n",
      "Requirement already satisfied: tensorboard>=1.14 in /home/crimex/miniconda3/lib/python3.10/site-packages (from thai-nner->pythainlp[full]) (2.11.2)\n",
      "Requirement already satisfied: termcolor in /home/crimex/miniconda3/lib/python3.10/site-packages (from fire>=0.1.3->attacut>=1.0.4->pythainlp[full]) (2.2.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /home/crimex/miniconda3/lib/python3.10/site-packages (from hydra-core<1.1,>=1.0.7->fairseq>=0.10.0->pythainlp[full]) (4.8)\n",
      "Requirement already satisfied: unicodecsv in /home/crimex/miniconda3/lib/python3.10/site-packages (from panphon>=0.20->epitran>=1.1->pythainlp[full]) (0.14.1)\n",
      "Requirement already satisfied: munkres in /home/crimex/miniconda3/lib/python3.10/site-packages (from panphon>=0.20->epitran>=1.1->pythainlp[full]) (1.1.4)\n",
      "Requirement already satisfied: editdistance in /home/crimex/miniconda3/lib/python3.10/site-packages (from panphon>=0.20->epitran>=1.1->pythainlp[full]) (0.6.2)\n",
      "Requirement already satisfied: portalocker in /home/crimex/miniconda3/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq>=0.10.0->pythainlp[full]) (2.7.0)\n",
      "Requirement already satisfied: lxml in /home/crimex/miniconda3/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq>=0.10.0->pythainlp[full]) (4.9.2)\n",
      "Requirement already satisfied: colorama in /home/crimex/miniconda3/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq>=0.10.0->pythainlp[full]) (0.4.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/crimex/miniconda3/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq>=0.10.0->pythainlp[full]) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in /home/crimex/.local/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (3.1.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (8.1.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (1.0.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (1.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (1.10.6)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (2.4.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (1.1.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorboard>=1.14->thai-nner->pythainlp[full]) (1.4.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorboard>=1.14->thai-nner->pythainlp[full]) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorboard>=1.14->thai-nner->pythainlp[full]) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorboard>=1.14->thai-nner->pythainlp[full]) (2.16.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorboard>=1.14->thai-nner->pythainlp[full]) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorboard>=1.14->thai-nner->pythainlp[full]) (2.2.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorboard>=1.14->thai-nner->pythainlp[full]) (1.51.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorboard>=1.14->thai-nner->pythainlp[full]) (1.8.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (3.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (2.11.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (1.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (1.6.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras<2.12,>=2.11.0\n",
      "  Using cached keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (0.31.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from tensorflow>=2.0.0->oskut>=1.3->pythainlp[full]) (15.0.6.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/crimex/.local/lib/python3.10/site-packages (from beautifulsoup4->fastai<2.0->pythainlp[full]) (2.3.2.post1)\n",
      "Requirement already satisfied: pycparser in /home/crimex/.local/lib/python3.10/site-packages (from cffi->fairseq>=0.10.0->pythainlp[full]) (2.21)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.10.0->pythainlp[full]) (10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from matplotlib->fastai<2.0->pythainlp[full]) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from matplotlib->fastai<2.0->pythainlp[full]) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/crimex/miniconda3/lib/python3.10/site-packages (from matplotlib->fastai<2.0->pythainlp[full]) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from matplotlib->fastai<2.0->pythainlp[full]) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from matplotlib->fastai<2.0->pythainlp[full]) (4.39.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from scikit-learn->oskut>=1.3->pythainlp[full]) (3.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/crimex/miniconda3/lib/python3.10/site-packages (from sympy->onnxruntime>=1.10.0->pythainlp[full]) (1.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->thai-nner->pythainlp[full]) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/crimex/miniconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->thai-nner->pythainlp[full]) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->thai-nner->pythainlp[full]) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->thai-nner->pythainlp[full]) (1.3.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/crimex/miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (0.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/crimex/miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.2.2->spacy-thai>=0.7.1->pythainlp[full]) (0.7.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/crimex/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=1.14->thai-nner->pythainlp[full]) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/crimex/miniconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->thai-nner->pythainlp[full]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/crimex/miniconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->thai-nner->pythainlp[full]) (3.2.2)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.1.6\n",
      "    Uninstalling Keras-2.1.6:\n",
      "      Successfully uninstalled Keras-2.1.6\n",
      "Successfully installed keras-2.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pythainlp[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35491f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a15e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9149e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187d884e",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb1cc10",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f98362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-19 21:17:53.353701: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-19 21:17:53.791253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-19 21:17:53.791302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-19 21:17:53.791307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "from tqdm import tqdm\n",
    "# pythainlp\n",
    "from pythainlp.tokenize import word_tokenize,subword_tokenize\n",
    "#  sentence segmentator\n",
    "from pythainlp.tokenize import sent_tokenize\n",
    "from pythainlp.tag import pos_tag\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import glob\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# thai cut\n",
    "thaicut=\"newmm\"\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate,train_test_split\n",
    "import pycrfsuite\n",
    "from pythainlp.corpus.common import thai_stopwords\n",
    "\n",
    "from transformers import (\n",
    "    CamembertTokenizer,\n",
    "    CamembertTokenizerFast, \n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7a8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(thai_stopwords())\n",
    "# stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6353f6",
   "metadata": {},
   "source": [
    "## Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a67c05",
   "metadata": {},
   "source": [
    "### OG WangchanBERTa Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec5acec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#จัดการประโยคซ้ำ\n",
    "data_not=[]\n",
    "def Unique(p):\n",
    "    text=re.sub(\"<[^>]*>\",\"\",p)\n",
    "    text=re.sub(\"\\[(.*?)\\]\",\"\",text)\n",
    "    text=re.sub(\"\\[\\/(.*?)\\]\",\"\",text)\n",
    "    if text not in data_not:\n",
    "        data_not.append(text)\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "333afa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เตรียมตัวตัด tag ด้วย re\n",
    "pattern = r'\\[\\[(.*?)\\]\\](.*?)\\[\\[\\/(.*?)\\]\\]'\n",
    "tokenizer = RegexpTokenizer(pattern) \n",
    "# ใช้ nltk.tokenize.RegexpTokenizer เพื่อตัด [TIME]8.00[/TIME] ให้เป็น ('TIME','ไง','TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97ad2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# จัดการกับ tag ที่ไม่ได้ tag\n",
    "def toolner_to_tag(text):\n",
    "    # text=text.strip().replace(\"FACILITY\",\"LOCATION\").replace(\"[AGO]\",\"\").replace(\"[/AGO]\",\"\").replace(\"[T]\",\"\").replace(\"[/T]\",\"\")\n",
    "    # !! change pattern \n",
    "    text=re.sub(\"<[[^>]]*>\",\"\",text)\n",
    "    text=re.sub(\"(\\[\\[\\/(.*?)\\]\\])\",\"\\\\1***\",text)#.replace('(\\[(.*?)\\])','***\\\\1')# text.replace('>','>***') # ตัดการกับพวกไม่มี tag word\n",
    "    text=re.sub(\"(\\[\\[\\w+\\]\\])\",\"***\\\\1\",text)\n",
    "    text2=[]\n",
    "    for i in text.split('***'):\n",
    "        if \"[[\" in i:\n",
    "            text2.append(i)\n",
    "        else:\n",
    "            text2.append(\"[[word]]\"+i+\"[[/word]]\")\n",
    "    text=\"\".join(text2)#re.sub(\"[word][/word]\",\"\",\"\".join(text2))\n",
    "    return text.replace(\"[[word]][[/word]]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2624b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# แปลง text ให้เป็น conll2002\n",
    "def text2conll2002(text,pos=False):\n",
    "    \"\"\"\n",
    "    ใช้แปลงข้อความให้กลายเป็น conll2002\n",
    "    \"\"\"\n",
    "    text=toolner_to_tag(text)\n",
    "    text=text.replace(\"''\",'\"')\n",
    "    text=text.replace(\"’\",'\"').replace(\"‘\",'\"')#.replace('\"',\"\")\n",
    "    text=re.sub(' +', ' ',text) # remove multiple whitespace !new added\n",
    "    tag=tokenizer.tokenize(text)\n",
    "    # print(\"Text : \", text)\n",
    "    # print(\"Tag : \", tag)\n",
    "    j=0\n",
    "    conll2002=\"\"\n",
    "    for tagopen,text,tagclose in tag:\n",
    "        word_cut = word_tokenize(text,engine=thaicut) # ใช้ตัวตัดคำ newmm จาก var ด้านบน (PyThaiNLP)\n",
    "        i=0\n",
    "        txt5=\"\"\n",
    "        while i<len(word_cut):\n",
    "            # print(i, \"-- \", word_cut[i])\n",
    "            if word_cut[i]==\"''\" or word_cut[i]=='\"':pass\n",
    "            elif i==0 and tagopen!='word':\n",
    "                txt5+=word_cut[i]\n",
    "                txt5+='\\t'+'B-'+tagopen\n",
    "                # print(\"B-\",tagopen)\n",
    "            elif tagopen!='word':\n",
    "                txt5+=word_cut[i]\n",
    "                txt5+='\\t'+'I-'+tagopen\n",
    "                # print(\"I-\",tagopen)\n",
    "            else:\n",
    "                txt5+=word_cut[i]\n",
    "                txt5+='\\t'+'O'\n",
    "                # print('O')\n",
    "            txt5+='\\n'\n",
    "            #j+=1\n",
    "            i+=1\n",
    "        conll2002+=txt5\n",
    "        # print(txt5)\n",
    "    if pos==False:\n",
    "        return conll2002\n",
    "    return postag(conll2002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7d8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ใช้สำหรับกำกับ pos tag เพื่อใช้กับ NER\n",
    "def postag(text):\n",
    "    listtxt=[i for i in text.split('\\n') if i!='']\n",
    "    list_word=[]\n",
    "    for data in listtxt:\n",
    "        list_word.append(data.split('\\t')[0])\n",
    "    #print(text)\n",
    "    list_word=pos_tag(list_word,engine=\"perceptron\", corpus=\"orchid\")\n",
    "    text=\"\"\n",
    "    i=0\n",
    "    for data in listtxt:\n",
    "        text+=data.split('\\t')[0]+'\\t'+list_word[i][1]+'\\t'+data.split('\\t')[1]+'\\n'\n",
    "        i+=1\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97f33e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# เขียนไฟล์ข้อมูล conll2002\n",
    "def write_conll2002(file_name,data):\n",
    "    \"\"\"\n",
    "    ใช้สำหรับเขียนไฟล์\n",
    "    \"\"\"\n",
    "    with codecs.open(file_name, \"w\", \"utf-8-sig\") as temp:\n",
    "        temp.write(data)\n",
    "    return True\n",
    "    \n",
    "# อ่านข้อมูลจากไฟล์\n",
    "def get_data(fileopen):\n",
    "    \"\"\"\n",
    "    สำหรับใช้อ่านทั้งหมดทั้งในไฟล์ทีละรรทัดออกมาเป็น list\n",
    "    \"\"\"\n",
    "    with codecs.open(fileopen, 'r',encoding='utf-8-sig') as f:\n",
    "        lines = f.read().splitlines()\n",
    "    return [a for a in tqdm(lines)] # เอาไม่ซ้ำกัน if Unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bec2fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alldata(lists):\n",
    "    text=\"\"\n",
    "    for data in lists:\n",
    "        text+=text2conll2002(data)\n",
    "        text+='\\n'\n",
    "    return text\n",
    "\n",
    "def alldata_list(lists):\n",
    "    data_all=[]\n",
    "    for data in lists:\n",
    "        data_num = []\n",
    "        try:\n",
    "            sents_text = sentence_seg(data)\n",
    "            sents_text = sentence_check(sents_text)\n",
    "            # print(\"Split sents --\",sents_text)\n",
    "            # print(\"Len -- \", len(sents_text), \"\\nType -- \", type(sents_text))\n",
    "\n",
    "            for sent in sents_text: \n",
    "                # pos = verb, noun (True or False)\n",
    "#                 print(\"Sent -- \", sent)\n",
    "                data_num=[]\n",
    "                txt=text2conll2002(sent,pos=True).split('\\n')\n",
    "                for d in txt:\n",
    "                    tt=d.split('\\t')\n",
    "                    if d!=\"\":\n",
    "                        if len(tt)==3: # pos=True\n",
    "                            data_num.append((tt[0],tt[1],tt[2]))\n",
    "                        else: # pos=False\n",
    "                            data_num.append((tt[0],tt[1]))\n",
    "                # print(data_num)\n",
    "                # print(\"Append - \", data_num)\n",
    "                data_all.append(data_num)\n",
    "                # print(\"pass\\n\")\n",
    "\n",
    "        except:\n",
    "            print(data)\n",
    "            print(\"not pass\\n\")\n",
    "    # print(data_all)\n",
    "    return data_all\n",
    "\n",
    "def alldata_list_str(lists):\n",
    "    string=\"\"\n",
    "    for data in lists:\n",
    "        string1=\"\"\n",
    "        for j in data:\n",
    "            string1+=j[0]+\"\t\"+j[1]+\"\t\"+j[2]+\"\\n\"\n",
    "        string1+=\"\\n\"\n",
    "        string+=string1\n",
    "    return string\n",
    "\n",
    "def get_data_tag(listd):\n",
    "    list_all=[]\n",
    "    c=[]\n",
    "    for i in listd:\n",
    "        if i !='':\n",
    "            c.append((i.split(\"\\t\")[0],i.split(\"\\t\")[1],i.split(\"\\t\")[2]))\n",
    "        else:\n",
    "            list_all.append(c)\n",
    "            c=[]\n",
    "    return list_all\n",
    "  \n",
    "def getall(lista):\n",
    "    ll=[]\n",
    "    for i in tqdm(lista):\n",
    "        o=True\n",
    "        for j in ll:\n",
    "            if re.sub(\"\\[(.*?)\\]\",\"\",i)==re.sub(\"\\[(.*?)\\]\",\"\",j):\n",
    "                o=False\n",
    "                break\n",
    "        if o==True:\n",
    "            ll.append(i)\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a09f2",
   "metadata": {},
   "source": [
    "### Added Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33338ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_xlsx(table, filepath):\n",
    "    table.to_excel(filepath+'.xlsx')\n",
    "    print(\"finished excel for \", filepath+'.xlsx')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6760fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(table, filepath):\n",
    "    table.to_csv(filepath+'.csv', encoding='utf-8-sig')\n",
    "    print(\"finished csv for \", filepath+'.csv')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4542959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_txt (table, filepath):\n",
    "    file = open(filepath+'.txt','w')\n",
    "    for item in table:\n",
    "        file.write(item+\"\\n\")\n",
    "    file.close()\n",
    "    print(\"finished txt for \", filepath+'.txt')\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1251b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_txt(li, filepath):\n",
    "    import pickle\n",
    "    with open(filepath+'.data', 'wb') as f:\n",
    "        pickle.dump(li, f)\n",
    "    print(\"END\")\n",
    "#     return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da9855ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_seg(text, en=\"crfcut\"):\n",
    "  # option - thaisum\n",
    "  return sent_tokenize(text , engine=en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc1a26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label(lists):\n",
    "    _tag = r'\\[\\[(.*?)\\]\\]'\n",
    "    pas = True \n",
    "    new_text = ''\n",
    "    checked_list = []\n",
    "\n",
    "    for ch_tag in lists: # loop ของประโยคที่ตัดออกมาแล้ว \n",
    "        # print(\"-----------------\") \n",
    "        # print(ch_tag)\n",
    "        find_tag = re. findall(_tag, ch_tag)\n",
    "\n",
    "        # ถ้่า tag ติดมาไม่ครบ\n",
    "        if len(find_tag)%2 != 0:\n",
    "            new_text += str(ch_tag)\n",
    "            pas = False \n",
    "          # print(\"Concat -- \", ch_tag)\n",
    "        # tag ครบ\n",
    "        if (len(re. findall(_tag, new_text))%2 == 0) and (new_text!= '') and (pas!= True):\n",
    "            pas = True\n",
    "            # print(\"condition!!  \", pas)\n",
    "\n",
    "        if pas == True: \n",
    "            if new_text != '': \n",
    "                checked_list.append(new_text)\n",
    "                # print(\"Added new_text -- \", new_text)\n",
    "                new_text = '' # re new_text to empty \n",
    "            else: \n",
    "                checked_list.append(ch_tag)\n",
    "                # print(\"Added ch_tag -- \", ch_tag)\n",
    "\n",
    "    return checked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ab7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_check(text):\n",
    "    checked_list = [] \n",
    "    # print(\"Text : \", text, \"\\n--------\")\n",
    "\n",
    "    checked_label = check_label(text)\n",
    "    # print(checked_list)\n",
    "\n",
    "    # print(\"sentence_checked : \",checked_label , \"\\n\")\n",
    "\n",
    "    checked_list.append(list(checked_label))\n",
    "    # print(len(checked_list)) # check จำนวนข่าวที่ loop\n",
    "\n",
    "    return checked_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7dc8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_check(lists):\n",
    "    # get list from alldata_list\n",
    "#     for text in lists:\n",
    "    for t in lists: \n",
    "#         print(t[2])\n",
    "        if '-' in t[2]:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4595b16",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d0f4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/home/crimex/CRIMEX/Dataset/last/final_data.txt'\n",
    "dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec5edca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 3466/3466 [00:00<00:00, 4473063.90it/s]\n",
      "100%|███████████████████████████████████████| 3466/3466 [01:09<00:00, 49.53it/s]\n"
     ]
    }
   ],
   "source": [
    "data1 = getall(get_data(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcd54b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3461\n"
     ]
    }
   ],
   "source": [
    "print(len(data1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c558c",
   "metadata": {},
   "source": [
    "### split train / test / val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b39ec49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO of NEWS\n",
      "Train:  2768\n",
      "Val:    346\n",
      "Test:   347\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# data is your entire dataset (including features and target variable)\n",
    "data2 = np.array(data1)\n",
    "# num_rows = data2.shape[0]\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Calculate the number of rows in the data\n",
    "num_rows = data2.shape[0]\n",
    "\n",
    "# Calculate the split points\n",
    "train_split = int(num_rows * train_ratio)\n",
    "val_split = int(num_rows * (train_ratio + val_ratio))\n",
    "\n",
    "# Split the data\n",
    "np.random.seed(50)\n",
    "train_data, val_data, test_data = np.split(data2, [train_split, val_split])\n",
    "\n",
    "# Print the lengths of the split data\n",
    "print(\"NO of NEWS\")\n",
    "print(\"Train: \",len(train_data))\n",
    "print(\"Val:   \",len(val_data))\n",
    "print(\"Test:  \",len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec48a49",
   "metadata": {},
   "source": [
    "### counting Token & Avg lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6e43729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8332/3324909410.py:5: FutureWarning: Possible nested set at position 2\n",
      "  text=re.sub(\"<[[^>]]*>\",\"\",text)\n"
     ]
    }
   ],
   "source": [
    "all_news = alldata_list(data2) #sent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce3b6a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74383"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a4a4151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcri=0\n",
    "tvic=0\n",
    "tenf=0\n",
    "tdate=0\n",
    "tloc=0\n",
    "titm=0\n",
    "tact=0\n",
    "twor=0\n",
    "troot=0\n",
    "ttrig=0\n",
    "\n",
    "lcri=[]\n",
    "lvic=[]\n",
    "lenf=[]\n",
    "ldate=[]\n",
    "lloc=[]\n",
    "litm=[]\n",
    "lact=[]\n",
    "lwor=[]\n",
    "lroot=[]\n",
    "ltrig=[]\n",
    "\n",
    "for n in all_news:\n",
    "    pretag ='start'\n",
    "    for token in n:\n",
    "#         print('pre//  ', pretag)\n",
    "        # count lenght \n",
    "        try: \n",
    "            t = token[2].split('-')\n",
    "            tag = t[1]\n",
    "        except:\n",
    "            tag='O'\n",
    "    \n",
    "        if tag!= 'O':\n",
    "            if pretag != tag: #and pretag!= 'O':\n",
    "#                 print('NEW LABEL - ', tag)\n",
    "                if tag == 'Criminal':\n",
    "                    tcri=1\n",
    "                elif tag == 'Victim':\n",
    "                    tvic=1\n",
    "                elif tag == 'Enforcement':\n",
    "                    tenf=1\n",
    "                elif tag == 'Datetime':\n",
    "                    tdate=1\n",
    "                elif tag == 'Location':\n",
    "                    tloc=1\n",
    "                elif tag == 'Item':\n",
    "                    titm=1\n",
    "                elif tag == 'Action':\n",
    "                    tact=1\n",
    "                elif tag == 'worth':\n",
    "                    twor=1\n",
    "                elif tag == 'Rootcause':\n",
    "                    troot=1\n",
    "                elif tag == 'Trigger':\n",
    "                    ttrig=1\n",
    "            else:\n",
    "#                 print('append - ', tag)\n",
    "                if tag == 'Criminal':\n",
    "                    tcri+=1\n",
    "                elif tag == 'Victim':\n",
    "                    tvic+=1\n",
    "                elif tag == 'Enforcement':\n",
    "                    tenf+=1\n",
    "                elif tag == 'Datetime':\n",
    "                    tdate+=1\n",
    "                elif tag == 'Location':\n",
    "                    tloc+=1\n",
    "                elif tag == 'Item':\n",
    "                    titm+=1\n",
    "                elif tag == 'Action':\n",
    "                    tact+=1\n",
    "                elif tag == 'worth':\n",
    "                    twor+=1\n",
    "                elif tag == 'Rootcause':\n",
    "                    troot+=1\n",
    "                elif tag == 'Trigger':\n",
    "                    ttrig+=1    \n",
    "#             pretag = tag\n",
    "                \n",
    "        # last token in label        \n",
    "#         if tag== 'O' and pretag!= 'O':\n",
    "        if pretag!= tag and pretag!='O' and pretag!='start':\n",
    "            if pretag == 'Criminal':\n",
    "                lcri.append(tcri)\n",
    "                tcri =0\n",
    "            elif pretag == 'Victim':\n",
    "                lvic.append(tvic)\n",
    "                tvic=0\n",
    "            elif pretag == 'Enforcement':\n",
    "                lenf.append(tenf)\n",
    "                tenf=0\n",
    "            elif pretag == 'Datetime':\n",
    "                ldate.append(tdate)\n",
    "                tdate=0\n",
    "            elif pretag == 'Location':\n",
    "                lloc.append(tloc)\n",
    "                tloc=0\n",
    "            elif pretag == 'Item':\n",
    "                litm.append(titm)\n",
    "                titm=0\n",
    "            elif pretag == 'Action':\n",
    "                lact.append(tact)\n",
    "                tact=0\n",
    "            elif pretag == 'worth':\n",
    "                lwor.append(twor)\n",
    "                twor=0\n",
    "            elif pretag == 'Rootcause':\n",
    "                lroot.append(troot)\n",
    "                troot=0\n",
    "            elif pretag == 'Trigger':\n",
    "                ltrig.append(ttrig)\n",
    "                ttrig=0\n",
    "            \n",
    "#             print('Add - ', pretag,'-', tag, ' -- ', token)\n",
    "#         print(tag)\n",
    "        pretag = tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "be2c14ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cri\n",
      "37958\n",
      "11.474607013301089\n",
      "vic\n",
      "27003\n",
      "11.204564315352696\n",
      "enf\n",
      "31784\n",
      "8.384067528356635\n",
      "date\n",
      "13634\n",
      "6.7428288822947575\n",
      "loc\n",
      "32821\n",
      "12.936933385888844\n",
      "item\n",
      "31329\n",
      "10.37727724412057\n",
      "act\n",
      "26271\n",
      "6.259471050750536\n",
      "worth\n",
      "17977\n",
      "6.0753632984116255\n",
      "root\n",
      "4693\n",
      "6.001278772378517\n",
      "trig\n",
      "7982\n",
      "5.943410275502606\n"
     ]
    }
   ],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "\n",
    "# find avg lenght and sum - token \n",
    "print('cri')\n",
    "print(sum(lcri))\n",
    "print(Average(lcri))\n",
    "print('vic')\n",
    "print(sum(lvic))\n",
    "print(Average(lvic))\n",
    "print('enf')\n",
    "print(sum(lenf))\n",
    "print(Average(lenf))\n",
    "print('date')\n",
    "print(sum(ldate))\n",
    "print(Average(ldate))\n",
    "print('loc')\n",
    "print(sum(lloc))\n",
    "print(Average(lloc))\n",
    "print('item')\n",
    "print(sum(litm))\n",
    "print(Average(litm))\n",
    "print('act')\n",
    "print(sum(lact))\n",
    "print(Average(lact))\n",
    "print('worth')\n",
    "print(sum(lwor))\n",
    "print(Average(lwor))\n",
    "print('root')\n",
    "print(sum(lroot))\n",
    "print(Average(lroot))\n",
    "print('trig')\n",
    "print(sum(ltrig))\n",
    "print(Average(ltrig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214e25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "464cc2bc",
   "metadata": {},
   "source": [
    "NO of NEWS\n",
    "Train:  2311\n",
    "Val:    289\n",
    "Test:   289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfac0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = alldata_list(train_data)\n",
    "test  = alldata_list(test_data)\n",
    "val   = alldata_list(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a05a38b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent train:  55410\n",
      "sent test :  9336\n",
      "sent val  :  9637\n"
     ]
    }
   ],
   "source": [
    "print(\"sent train: \", len(train))\n",
    "print(\"sent test : \", len(test))\n",
    "print(\"sent val  : \", len(val))\n",
    "\n",
    "# sent train:  50521\n",
    "# sent test :  8194\n",
    "# sent val  :  8861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a7987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "259b4227",
   "metadata": {},
   "source": [
    "### sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64aa72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to txt file \n",
    "# format text tag\n",
    "import re\n",
    "\n",
    "def to_txt_bert(data, filepath):\n",
    "    count =0\n",
    "    uncount=0\n",
    "    with open( filepath+'.txt', 'w') as file:\n",
    "#         file.write(\"-DOCSTART- O\\n\\n\")\n",
    "        for item in data:\n",
    "\n",
    "            for t in item: \n",
    "                if t[0] != ' ': # remove spacebar char\n",
    "                    file.write(t[0])\n",
    "                    file.write(\"|\")\n",
    "                    file.write(t[2])\n",
    "                    file.write(\"\\n\")\n",
    "            file.write('\\n')\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    print(filepath)\n",
    "    print('OG len : ', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf42e78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/crimex/CRIMEX/Dataset/bert/sent/final/bert_train\n",
      "OG len :  55410\n",
      "/home/crimex/CRIMEX/Dataset/bert/sent/final/bert_test\n",
      "OG len :  9336\n",
      "/home/crimex/CRIMEX/Dataset/bert/sent/final/bert_val\n",
      "OG len :  9637\n"
     ]
    }
   ],
   "source": [
    "catt = 'final'\n",
    "b_train_path = '/home/crimex/CRIMEX/Dataset/bert/sent/'+catt+'/bert_train'\n",
    "b_test_path  = '/home/crimex/CRIMEX/Dataset/bert/sent/'+catt+'/bert_test'\n",
    "b_val_path   = '/home/crimex/CRIMEX/Dataset/bert/sent/'+catt+'/bert_val'\n",
    "\n",
    "to_txt_bert(train, b_train_path)\n",
    "to_txt_bert(test, b_test_path)\n",
    "to_txt_bert(val, b_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34781c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a482cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def li_to_txt_liform(data, filepath):\n",
    "    count =0\n",
    "    uncount=0\n",
    "    with open(filepath+'.txt', \"w\") as f:\n",
    "        for item in data:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    f.close()       \n",
    "    print(filepath)\n",
    "    print('OG len : ', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e3b5690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/crimex/CRIMEX/Dataset/crf/sent/train_final\n",
      "OG len :  55410\n",
      "/home/crimex/CRIMEX/Dataset/crf/sent/test_final\n",
      "OG len :  9336\n"
     ]
    }
   ],
   "source": [
    "di = '/home/crimex/CRIMEX/Dataset/crf/sent/'\n",
    "test_path = di + 'test_'+catt\n",
    "train_path = di + 'train_'+catt\n",
    "\n",
    "li_to_txt_liform(train, train_path)\n",
    "li_to_txt_liform(test, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427129d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e056bf",
   "metadata": {},
   "source": [
    "### Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85889e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7577\n",
      "1226\n",
      "1247\n"
     ]
    }
   ],
   "source": [
    "def chunk_news(data):\n",
    "    conti = []\n",
    "    news_chunk = []\n",
    "    index = 0\n",
    "    \n",
    "    for item in data:\n",
    "#         print(\"index\", index)\n",
    "#         print('ind len: ', len(item))\n",
    "        \n",
    "        # first element in data\n",
    "        if index == 0:\n",
    "            conti = item\n",
    "#             print(\"First -- \", len(conti))\n",
    "            \n",
    "        else: \n",
    "            if len(conti) + len(item) > 200 or item[0][0] == '[::':\n",
    "                news_chunk.append(list(conti))\n",
    "#                 print('New ', len(conti), '+', len(item), '=', len(conti) + len(item), ' - ', item[0])\n",
    "                conti = item\n",
    "            else:\n",
    "                conti += item\n",
    "#                 print(\"---------add\")\n",
    "\n",
    "            #last element in data\n",
    "            if index == len(data)-1 : \n",
    "                news_chunk.append(list(conti))\n",
    "#                 print('Last')\n",
    "        \n",
    "        index+=1\n",
    "                \n",
    "    return news_chunk \n",
    "\n",
    "\n",
    "test_chunk = chunk_news(alldata_list(test_data))\n",
    "val_chunk = chunk_news(alldata_list(val_data))\n",
    "train_chunk = chunk_news(alldata_list(train_data))\n",
    "\n",
    "print(len(train_chunk))\n",
    "print(len(test_chunk))\n",
    "print(len(val_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb65e4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/crimex/CRIMEX/Dataset/crf/chunk/train_final\n",
      "OG len :  7577\n",
      "/home/crimex/CRIMEX/Dataset/crf/chunk/test_final\n",
      "OG len :  1226\n"
     ]
    }
   ],
   "source": [
    "di = '/home/crimex/CRIMEX/Dataset/crf/chunk/'\n",
    "test_path = di + 'test_'+catt\n",
    "train_path = di + 'train_'+catt\n",
    "\n",
    "li_to_txt_liform(train_chunk, train_path)\n",
    "li_to_txt_liform(test_chunk, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48f1edd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/crimex/CRIMEX/Dataset/bert/chunk/final/bert_train\n",
      "OG len :  7577\n",
      "/home/crimex/CRIMEX/Dataset/bert/chunk/final/bert_test\n",
      "OG len :  1226\n",
      "/home/crimex/CRIMEX/Dataset/bert/chunk/final/bert_val\n",
      "OG len :  1247\n"
     ]
    }
   ],
   "source": [
    "# data for BERT model\n",
    "b_train_path = '/home/crimex/CRIMEX/Dataset/bert/chunk/'+catt+'/bert_train'\n",
    "b_test_path  = '/home/crimex/CRIMEX/Dataset/bert/chunk/'+catt+'/bert_test'\n",
    "b_val_path   = '/home/crimex/CRIMEX/Dataset/bert/chunk/'+catt+'/bert_val'\n",
    "\n",
    "to_txt_bert(train_chunk, b_train_path)\n",
    "to_txt_bert(test_chunk, b_test_path)\n",
    "to_txt_bert(val_chunk, b_val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaf77f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61208366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99e0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554b515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4c9c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b16e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
